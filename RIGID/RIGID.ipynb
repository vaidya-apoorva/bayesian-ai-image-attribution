{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55a4c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import random\n",
    "import os\n",
    "import sys\n",
    "from sklearn import metrics\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, datasets\n",
    "import torchvision.transforms.functional as TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "719362af",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 100\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0ddaeb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_auc(similarities, datasets):\n",
    "    \"\"\"\n",
    "    Calculate AUC and FPR95 for multiple OOD datasets against ID dataset.\n",
    "    \n",
    "    Args:\n",
    "        similarities (list): List of similarity arrays, first one is ID dataset\n",
    "        datasets (list): List of dataset names\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (average_auc, average_fpr95)\n",
    "    \"\"\"\n",
    "    if len(similarities) != len(datasets):\n",
    "        raise ValueError(\"Number of similarities arrays must match number of dataset names\")\n",
    "    \n",
    "    if len(similarities) < 2:\n",
    "        raise ValueError(\"At least 2 datasets (ID and OOD) are required\")\n",
    "\n",
    "    similarities = np.array(similarities, dtype=object)  # Use object dtype for arrays of different lengths\n",
    "    id_confi = similarities[0]\n",
    "\n",
    "    auc_scores = []\n",
    "    fpr_scores = []\n",
    "\n",
    "    for ood_confi, dataset in zip(similarities[1:], datasets[1:]):\n",
    "        auroc, fpr_95 = calculate_auc_metrics(id_confi, ood_confi)\n",
    "        auc_scores.append(auroc)\n",
    "        fpr_scores.append(fpr_95)\n",
    "        print(f\"Dataset: {dataset:<25} | AUC: {auroc:.4f} | FPR95: {fpr_95:.4f}\")\n",
    "    \n",
    "    avg_auc = np.mean(auc_scores)\n",
    "    avg_fpr = np.mean(fpr_scores)\n",
    "    \n",
    "    print(\"-\" * 60)\n",
    "    print(f\"Average AUC: {avg_auc:.4f} | Average FPR95: {avg_fpr:.4f}\")\n",
    "    \n",
    "    return avg_auc, avg_fpr\n",
    "\n",
    "\n",
    "def sim_ap(similarities, datasets):\n",
    "    \"\"\"\n",
    "    Calculate Average Precision for multiple OOD datasets against ID dataset.\n",
    "    \n",
    "    Args:\n",
    "        similarities (list): List of similarity arrays, first one is ID dataset\n",
    "        datasets (list): List of dataset names\n",
    "        \n",
    "    Returns:\n",
    "        float: average AP score\n",
    "    \"\"\"\n",
    "    if len(similarities) != len(datasets):\n",
    "        raise ValueError(\"Number of similarities arrays must match number of dataset names\")\n",
    "\n",
    "    if len(similarities) < 2:\n",
    "        raise ValueError(\"At least 2 datasets (ID and OOD) are required\")\n",
    "\n",
    "    similarities = np.array(similarities, dtype=object)\n",
    "    id_confi = similarities[0]\n",
    "\n",
    "    ap_scores = []\n",
    "\n",
    "    for ood_confi, dataset in zip(similarities[1:], datasets[1:]):\n",
    "        aver_p = calculate_average_precision(id_confi, ood_confi)\n",
    "        ap_scores.append(aver_p)\n",
    "        print(f\"Dataset: {dataset:<25} | AP: {aver_p:.4f}\")\n",
    "    \n",
    "    avg_ap = np.mean(ap_scores)\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"Average AP: {avg_ap:.4f}\")\n",
    "    \n",
    "    return avg_ap\n",
    "\n",
    "\n",
    "def calculate_auc_metrics(id_conf, ood_conf):\n",
    "    \"\"\"\n",
    "    Calculate AUROC and FPR at 95% TPR for binary classification.\n",
    "    \n",
    "    Args:\n",
    "        id_conf (np.ndarray): Confidence scores for ID (in-distribution) samples\n",
    "        ood_conf (np.ndarray): Confidence scores for OOD (out-of-distribution) samples\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (auroc, fpr_at_95_tpr)\n",
    "    \"\"\"\n",
    "    # Combine predictions and create labels\n",
    "    all_conf = np.concatenate([id_conf, ood_conf])\n",
    "    # ID samples are positive (1), OOD samples are negative (0)\n",
    "    labels = np.concatenate([np.ones(len(id_conf)), np.zeros(len(ood_conf))])\n",
    "    \n",
    "    # Calculate ROC curve\n",
    "    fpr, tpr, _ = metrics.roc_curve(labels, all_conf)\n",
    "    \n",
    "    # Calculate AUROC\n",
    "    auroc = metrics.auc(fpr, tpr)\n",
    "    \n",
    "    # Calculate FPR at 95% TPR\n",
    "    tpr_threshold = 0.95\n",
    "    valid_indices = tpr >= tpr_threshold\n",
    "    if np.any(valid_indices):\n",
    "        fpr_at_95 = fpr[np.argmax(valid_indices)]\n",
    "    else:\n",
    "        fpr_at_95 = fpr[-1]\n",
    "        print(f\"Warning: 95% TPR not achievable. Max TPR: {tpr[-1]:.3f}\")\n",
    "    \n",
    "    return auroc, fpr_at_95\n",
    "\n",
    "\n",
    "def calculate_average_precision(id_predictions, ood_predictions):\n",
    "\n",
    "    # Combine predictions and create labels\n",
    "    all_predictions = np.concatenate([id_predictions, ood_predictions])\n",
    "    # ID samples are positive (1), OOD samples are negative (0)\n",
    "    labels = np.concatenate([np.ones(len(id_predictions)), np.zeros(len(ood_predictions))])\n",
    "    \n",
    "    # Calculate Average Precision\n",
    "    average_precision = metrics.average_precision_score(labels, all_predictions)\n",
    "    \n",
    "    return average_precision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf74f746",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_MEAN = (0.485, 0.456, 0.406)\n",
    "DEFAULT_STD = (0.229, 0.224, 0.225)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b43af8",
   "metadata": {},
   "source": [
    "# Define RIGID Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5420d727",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RIGID_Detector():\n",
    "    \n",
    "    def __init__(self, lamb=0.05, percentile=5):\n",
    "        \n",
    "        self.lamb = lamb\n",
    "        self.model = torch.hub.load('facebookresearch/dinov2', 'dinov2_vitl14').cuda()\n",
    "        self.model.eval()\n",
    "        \n",
    "    @torch.no_grad()\n",
    "    def calculate_sim(self, data):\n",
    "        features = self.model(data)\n",
    "        noise = torch.randn_like(data).to(data.device)\n",
    "        trans_data = data + noise * self.lamb\n",
    "        trans_features = self.model(trans_data)\n",
    "        sim_feat = F.cosine_similarity(features, trans_features, dim=-1)\n",
    "        return sim_feat\n",
    "\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def detect(self, data):\n",
    "        sim = self.calculate_sim(data)\n",
    "        return sim\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f96290a",
   "metadata": {},
   "source": [
    "# Detection AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f8ab55",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_RIGID = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=DEFAULT_MEAN, std=DEFAULT_STD),\n",
    "    ])\n",
    "\n",
    "# Test Datasets \n",
    "# You can test multiple datasets\n",
    "# But make sure the real image dataset is in the first one to facilitate the calculation of AUC or AP.\n",
    "test_datasets = ['Imagenet', 'Imagenet256-ADM', 'Imagenet256-ADMG', 'Imagenet256-LDM', 'Imagenet256-DiT-XL-2', \n",
    "                     'Imagenet256-BigGAN', 'Imagenet256-GigaGAN', 'Imagenet256-StyleGAN-XL', 'Imagenet256-RQ-Transformer', 'Imagenet256-Mask-GIT']\n",
    "noise_intensity = 0.05\n",
    "batch_size = 256\n",
    "\n",
    "rigid_detector = RIGID_Detector(lamb=noise_intensity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51cd8b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imagenet, Image number: 1024, similarity is 0.9924506545066833\n",
      "Imagenet256-ADM, Image number: 1024, similarity is 0.9651902914047241\n",
      "Imagenet256-ADM, Image number: 1024, similarity is 0.9651902914047241\n",
      "Imagenet256-ADMG, Image number: 1024, similarity is 0.9730035066604614\n",
      "Imagenet256-ADMG, Image number: 1024, similarity is 0.9730035066604614\n",
      "Imagenet256-LDM, Image number: 1024, similarity is 0.9707759022712708\n",
      "Imagenet256-LDM, Image number: 1024, similarity is 0.9707759022712708\n",
      "Imagenet256-DiT-XL-2, Image number: 1024, similarity is 0.9813703298568726\n",
      "Imagenet256-DiT-XL-2, Image number: 1024, similarity is 0.9813703298568726\n",
      "Imagenet256-BigGAN, Image number: 1024, similarity is 0.9487172961235046\n",
      "Imagenet256-BigGAN, Image number: 1024, similarity is 0.9487172961235046\n",
      "Imagenet256-GigaGAN, Image number: 1024, similarity is 0.9642414450645447\n",
      "Imagenet256-GigaGAN, Image number: 1024, similarity is 0.9642414450645447\n",
      "Imagenet256-StyleGAN-XL, Image number: 1024, similarity is 0.9728654623031616\n",
      "Imagenet256-StyleGAN-XL, Image number: 1024, similarity is 0.9728654623031616\n",
      "Imagenet256-RQ-Transformer, Image number: 1024, similarity is 0.9490829706192017\n",
      "Imagenet256-RQ-Transformer, Image number: 1024, similarity is 0.9490829706192017\n",
      "Imagenet256-Mask-GIT, Image number: 1024, similarity is 0.9511527419090271\n",
      "Detection Results AUC:\n",
      "Dataset: Imagenet256-ADM           | AUC: 0.8773 | FPR95: 0.4609\n",
      "Dataset: Imagenet256-ADMG          | AUC: 0.8334 | FPR95: 0.5713\n",
      "Dataset: Imagenet256-LDM           | AUC: 0.8215 | FPR95: 0.5820\n",
      "Dataset: Imagenet256-DiT-XL-2      | AUC: 0.7249 | FPR95: 0.7217\n",
      "Dataset: Imagenet256-BigGAN        | AUC: 0.9397 | FPR95: 0.2744\n",
      "Dataset: Imagenet256-GigaGAN       | AUC: 0.8934 | FPR95: 0.4404\n",
      "Dataset: Imagenet256-StyleGAN-XL   | AUC: 0.8601 | FPR95: 0.5625\n",
      "Dataset: Imagenet256-RQ-Transformer | AUC: 0.9377 | FPR95: 0.2871\n",
      "Dataset: Imagenet256-Mask-GIT      | AUC: 0.9241 | FPR95: 0.3223\n",
      "------------------------------------------------------------\n",
      "Average AUC: 0.8680 | Average FPR95: 0.4692\n",
      "Detection Results AP:\n",
      "Dataset: Imagenet256-ADM           | AP: 0.8611\n",
      "Dataset: Imagenet256-ADMG          | AP: 0.8133\n",
      "Dataset: Imagenet256-LDM           | AP: 0.8067\n",
      "Dataset: Imagenet256-DiT-XL-2      | AP: 0.6999\n",
      "Dataset: Imagenet256-BigGAN        | AP: 0.9337\n",
      "Dataset: Imagenet256-GigaGAN       | AP: 0.8792\n",
      "Dataset: Imagenet256-StyleGAN-XL   | AP: 0.8484\n",
      "Dataset: Imagenet256-RQ-Transformer | AP: 0.9346\n",
      "Dataset: Imagenet256-Mask-GIT      | AP: 0.9176\n",
      "----------------------------------------\n",
      "Average AP: 0.8549\n",
      "Imagenet256-Mask-GIT, Image number: 1024, similarity is 0.9511527419090271\n",
      "Detection Results AUC:\n",
      "Dataset: Imagenet256-ADM           | AUC: 0.8773 | FPR95: 0.4609\n",
      "Dataset: Imagenet256-ADMG          | AUC: 0.8334 | FPR95: 0.5713\n",
      "Dataset: Imagenet256-LDM           | AUC: 0.8215 | FPR95: 0.5820\n",
      "Dataset: Imagenet256-DiT-XL-2      | AUC: 0.7249 | FPR95: 0.7217\n",
      "Dataset: Imagenet256-BigGAN        | AUC: 0.9397 | FPR95: 0.2744\n",
      "Dataset: Imagenet256-GigaGAN       | AUC: 0.8934 | FPR95: 0.4404\n",
      "Dataset: Imagenet256-StyleGAN-XL   | AUC: 0.8601 | FPR95: 0.5625\n",
      "Dataset: Imagenet256-RQ-Transformer | AUC: 0.9377 | FPR95: 0.2871\n",
      "Dataset: Imagenet256-Mask-GIT      | AUC: 0.9241 | FPR95: 0.3223\n",
      "------------------------------------------------------------\n",
      "Average AUC: 0.8680 | Average FPR95: 0.4692\n",
      "Detection Results AP:\n",
      "Dataset: Imagenet256-ADM           | AP: 0.8611\n",
      "Dataset: Imagenet256-ADMG          | AP: 0.8133\n",
      "Dataset: Imagenet256-LDM           | AP: 0.8067\n",
      "Dataset: Imagenet256-DiT-XL-2      | AP: 0.6999\n",
      "Dataset: Imagenet256-BigGAN        | AP: 0.9337\n",
      "Dataset: Imagenet256-GigaGAN       | AP: 0.8792\n",
      "Dataset: Imagenet256-StyleGAN-XL   | AP: 0.8484\n",
      "Dataset: Imagenet256-RQ-Transformer | AP: 0.9346\n",
      "Dataset: Imagenet256-Mask-GIT      | AP: 0.9176\n",
      "----------------------------------------\n",
      "Average AP: 0.8549\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "\n",
    "        sim_datasets = []\n",
    "        for dataset in test_datasets:\n",
    "\n",
    "            dataset_folder = datasets.ImageFolder(root=f'./gen_images/{dataset}',  transform=transform_RIGID)\n",
    "\n",
    "            data_loader = DataLoader(dataset_folder, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "            sim_feat = []\n",
    "            total_num = 0 \n",
    "            for i, (samples, _) in enumerate(data_loader):\n",
    "                \n",
    "                samples = samples.cuda()\n",
    "                samples_num = len(samples)\n",
    "                total_num += samples_num\n",
    "\n",
    "                sim = rigid_detector.calculate_sim(samples)\n",
    "                sim_feat.append(sim)\n",
    "\n",
    "                if total_num >= 1000: break\n",
    "            \n",
    "            sim_feat = torch.cat(sim_feat, dim=0)\n",
    "            print(f'{dataset}, Image number: {sim_feat.shape[0]}, similarity is {sim_feat.mean().item()}')\n",
    "\n",
    "            sim_datasets.append(sim_feat.cpu().numpy())\n",
    "        \n",
    "        print(\"Detection Results AUC:\")\n",
    "        sim_auc(sim_datasets, test_datasets)\n",
    "\n",
    "        print(\"Detection Results AP:\")\n",
    "        sim_ap(sim_datasets, test_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2aea9af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gen_detect",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
