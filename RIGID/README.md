# RIGID: A Training-free and Model-Agnostic Framework for Robust AI-Generated Image Detection

> The rapid advances in generative AI models have empowered the creation of highly realistic images with arbitrary content, raising concerns about potential misuse and harm, such as Deepfakes. Current research focuses on training detectors using large datasets of generated images. However, these training-based solutions are often computationally expensive and show limited generalization to unseen generated images. In this paper, we propose a training-free method to distinguish between real and AI-generated images. We first observe that real images are more robust to tiny noise perturbations than AI-generated images in the representation space of vision foundation models. Based on this observation, we propose RIGID, a training-free and model-agnostic method for robust AI-generated image detection. RIGID is a simple yet effective approach that identifies whether an image is AI-generated by comparing the representation similarity between the original and the noise-perturbed counterpart. Our evaluation on a diverse set of AI-generated images and benchmarks shows that RIGID significantly outperforms existing trainingbased and training-free detectors. In particular, the average performance of RIGID exceeds the current best training-free method by more than 25%. Importantly, RIGID exhibits strong generalization across different image generation methods and robustness to image corruptions.


# Run the code

1. Download Generated Datasets
    * ImageNet [9 generated methods](https://drive.google.com/drive/folders/1X0MFaUta90d3zF9xG4KchjR-8SE0cT_7?usp=sharing), including ADM, ADMG, LDM, DiT-XL2, BigGAN, GigaGAN, StyleGAN-XL, RQ-Transformer, Mask-GIT.
    * LSUN-Bedroom [7 generated methods](https://drive.google.com/drive/folders/1X0MFaUta90d3zF9xG4KchjR-8SE0cT_7?usp=sharing), including ADM, DDPM, iDDPM, Diffusion Projected GAN, Projected GAN, Style GAN, Unleashing Transformer. 
        * **Note that all the images in ImageNet and LSUN-Bedroom are from the paper [Exposing flaws of generative model evaluation metrics and their unfair treatment of diffusion models](https://github.com/layer6ai-labs/dgm-eval/tree/master?tab=readme-ov-file)**
    * GenImage [A Million-Scale Benchmark for Detecting AI-Generated Image](https://github.com/GenImage-Dataset/GenImage)

    **Place the downloaded dataset in the gen_images folder.**

2. Detect

>
See the steps in the RIGID.ipynb



